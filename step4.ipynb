{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA->Image Clustering: Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autotime\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "import joblib\n",
    "\n",
    "from cls import *\n",
    "\n",
    "#All clustering algorithms have been imported here\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, SpectralClustering, OPTICS\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dataset \"Y\" will be used in clustering\n",
    "Y = joblib.load('Y.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior to Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following code is from https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html\n",
    "\n",
    "#This block will calculate average silhouette score given a data set and a number of clusters\n",
    "#The number of clusters with the maximum average silhouette score provides a theoretically optimal parameter for number \n",
    "#of clusters, at least for the K-Means algorithm.\n",
    "\n",
    "#Enter or create a list of check values and the code will go through each value and calculate the average silhouette score\n",
    "#for each test value. To start out, it may be wise to test a range of values to get an idea for what size of numbers to expect.\n",
    "range_n_clusters = [9,29,33,41,42,43]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(Y) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(Y)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(Y, cluster_labels)\n",
    "    print(\n",
    "        \"For n_clusters =\",\n",
    "        n_clusters,\n",
    "        \"The average silhouette_score is :\",\n",
    "        silhouette_avg,\n",
    "    )\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(Y, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            ith_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(\n",
    "        Y[:, 0], Y[:, 1], marker=\".\", s=30, lw=0, alpha=0.7, c=colors, edgecolor=\"k\"\n",
    "    )\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(\n",
    "        centers[:, 0],\n",
    "        centers[:, 1],\n",
    "        marker=\"o\",\n",
    "        c=\"white\",\n",
    "        alpha=1,\n",
    "        s=200,\n",
    "        edgecolor=\"k\",\n",
    "    )\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker=\"$%d$\" % i, alpha=1, s=50, edgecolor=\"k\")\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        \"Silhouette analysis for KMeans clustering on sample data with n_clusters = %d\"\n",
    "        % n_clusters,\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following code is from https://medium.com/@tarammullin/dbscan-parameter-estimation-ff8330e3a3bd\n",
    "#written and explained by Tara Mullin in 2020\n",
    "\n",
    "#This is used for estimating epsilon in DBSCAN clustering\n",
    "#the article also has information about choosing minpts\n",
    "\n",
    "#In order to estimate a good number for epsilon, look for the \"elbow\" point in the plot where the concavity magnitude is \n",
    "#maximum and the corresponding value on the vertical axis will be the estimate for epsilon.\n",
    "\n",
    "\n",
    "minpts = 4\n",
    "                                                   \n",
    "from sklearn.neighbors import NearestNeighbors     \n",
    "\n",
    "neighbors = NearestNeighbors(n_neighbors= minpts)\n",
    "neighbors_fit = neighbors.fit(Y)\n",
    "distances, indices = neighbors_fit.kneighbors(Y)\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]\n",
    "plt.plot(distances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K    = 32\n",
    "#kmap = KMeans(n_clusters=K).fit_predict(Y)\n",
    "#above is the old Kmeans code\n",
    "\n",
    "#user input will be requested below when the block is run\n",
    "\n",
    "print('Note: For the clustering comparisons between two algorithms in the next notebook,')\n",
    "print('      you should ensure that the two algorithms that you wish to compare have the')\n",
    "print('      same number of clusters. As DBSCAN and OPTICS do not take a number of clusters')\n",
    "print('      in as a parameter, you should enter appropriate matching numbers of clusters')\n",
    "print('      for the other algorithms that do, should you wish to compare them effectively.')\n",
    "print()\n",
    "print('Abbreviations:')\n",
    "print('\"k\" for K-means')\n",
    "print('\"a\" for Agglomerative')\n",
    "print('\"d\" for DBSCAN')\n",
    "print('\"s\" for Spectral')\n",
    "print('\"o\" for OPTICS')\n",
    "\n",
    "\n",
    "#Below is where the various algorithms are kept as functions.\n",
    "\n",
    "#Instructions for implementing more algorithms:\n",
    "\n",
    "#1. Define a new function in this section which returns the clustering result as an array containing the cluster\n",
    "#   indices, with index -1 representing outliers if the algorithm supports them. \n",
    "\n",
    "#   During this process, you will have to think of a characteristic letter or letters to represent the new algorithm. \n",
    "#   This letter or letters will be what a user will enter in the user input for selecting which algorithms to use.\n",
    "#   It will also give you a label for the algorithm in the next steps\n",
    "\n",
    "#2. Initialize a new np.zeros - 1 integer array corresponding to the new clustering function. Use the other np.zeros - 1 \n",
    "#   arrays as templates.\n",
    "\n",
    "#3. Write a new \"if\" statement in the \"for i in algo:\" loop using the other algorithms as templates. This conditional\n",
    "#   should have the corresponding function return a cluster index array. \n",
    "\n",
    "#   For any algorithm that does not take in a number of clusters as an input parameter, it will be useful to print the \n",
    "#   number of clusters the algorithm ended up with, such that the same number of clusters can be ensured for each algorithm.\n",
    "#   This is necessary to compare the algorithms later (Use DBSCAN and OPTICS as templates for counting clusters).\n",
    "\n",
    "#4. Put your new cluster index array into the \"kmap\" verical stack and take note of which row your new array occupies\n",
    "#   in \"kmap\" as this will be used in the visualization below and the comparison later.\n",
    "\n",
    "#   After all of this, each algorithm should have a characeristic letter or letters and a row index identifying it\n",
    "#   ex. K-Means is k and 0, Agglomerative is a and 1, etc.\n",
    "\n",
    "#==============================================================================\n",
    "#=========================BEGINNING OF ALGORITHMS==============================\n",
    "#==============================================================================\n",
    "\n",
    "\n",
    "#Kmeans++ clustering (centroid-based)\n",
    "def K(X):\n",
    "    nclus = int(input('Enter a presumed number of clusters for the data set (integers only) (k): '))\n",
    "    km = KMeans(n_clusters=nclus, init='k-means++', n_init=10, max_iter=10000,\n",
    "                tol=1e-4, random_state=0)\n",
    "    a = km.fit_predict(X)\n",
    "    return a\n",
    "\n",
    "\n",
    "#Agglomerative clustering (hierarchical)\n",
    "def A(X):\n",
    "    nclus = int(input('Enter a presumed number of clusters for the data set (integers only) (a): '))\n",
    "    ac = AgglomerativeClustering(n_clusters=nclus, affinity='euclidean',\n",
    "                                 linkage='complete')\n",
    "    return ac.fit_predict(X)\n",
    "\n",
    "\n",
    "#DBSCAN clustering (density-based)\n",
    "def D(X):\n",
    "    minpts = int(input('Enter the minimum closest neighbors to be considered a core point (integers only) (d): '))\n",
    "    ep = float(input('Enter \"epsilon\", the distance within which two points will be considered neighboring points (floats okay) (o): '))\n",
    "    db = DBSCAN(eps=ep, min_samples=minpts, metric='euclidean')\n",
    "    return db.fit_predict(X)\n",
    "\n",
    "\n",
    "#Spectral clustering\n",
    "def S(X):\n",
    "    nclus = int(input('Enter a presumed number of clusters for the data set (integers only) (s): '))\n",
    "    sc = SpectralClustering(n_clusters = nclus, eigen_tol = 1e-3)\n",
    "    return sc.fit_predict(X)  #Try later feeding in fewer images, different eigensolvers\n",
    "\n",
    "\n",
    "#OPTICS clustering\n",
    "def O(X):\n",
    "    minmem = float(input('Enter the minimum closest neighbors to be considered a core point (integer or fraction of total points) (o): '))\n",
    "    ep = float(input('Enter \"epsilon_max\", the maximum radius between neighboring points (infinite by default) (floats okay) (o): '))\n",
    "    if minmem > 1:\n",
    "        minmem = int(minmem)\n",
    "    op = OPTICS(min_samples = minmem, max_eps = ep)\n",
    "    return op.fit_predict(X)\n",
    "\n",
    "\n",
    "#==============================================================================\n",
    "#=============================END OF ALGORITHMS================================\n",
    "#==============================================================================\n",
    "\n",
    "\n",
    "print()\n",
    "print('Which algorithms would you like to use? (enter the appropriate abbreviations shown above')\n",
    "algo = input('and separate multiple algorithms with spaces): ')\n",
    "print()\n",
    "\n",
    "kmap_k = np.zeros(len(Y), int) - 1\n",
    "kmap_a = np.zeros(len(Y), int) - 1\n",
    "kmap_d = np.zeros(len(Y), int) - 1\n",
    "kmap_s = np.zeros(len(Y), int) - 1\n",
    "kmap_o = np.zeros(len(Y), int) - 1\n",
    "\n",
    "for i in algo:\n",
    "    if i == 'k':\n",
    "        kmap_k = K(Y)\n",
    "    if i == 'a':\n",
    "        kmap_a = A(Y)\n",
    "    if i == 'd':\n",
    "        kmap_d = D(Y)\n",
    "        maximum = 0\n",
    "        for i in kmap_d:\n",
    "            if i > maximum:\n",
    "                maximum = i\n",
    "        print('DBSCAN with the given parameters resulted in',maximum + 1,'clusters')\n",
    "    if i == 's':\n",
    "        kmap_s = S(Y)\n",
    "    if i == 'o':\n",
    "        kmap_o = O(Y)\n",
    "        maximum = 0\n",
    "        for i in kmap_o:\n",
    "            if i > maximum:\n",
    "                maximum = i\n",
    "        print('OPTICS with the given parameters resulted in',maximum + 1,'clusters')\n",
    "        \n",
    "kmap = np.vstack((kmap_k, kmap_a, kmap_d, kmap_s, kmap_o))\n",
    "print(kmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(kmap, 'kmap.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_results = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300).fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reminder: k is 0, a is 1, d is 2, s is 3, o is 4\n",
    "#Enter the kmap row index of the algorithm you would like to visualize the clustering of\n",
    "\n",
    "alg = 1\n",
    "\n",
    "kc   = dict(zip(*np.unique(kmap, return_counts=True)))\n",
    "keys = list({k: v for k, v in sorted(kc.items(), key=lambda v: v[1], reverse=True)}.keys())\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "for k in keys:\n",
    "    plt.scatter([tsne_results[w,0] for w in np.where(kmap[alg] == k)[0]],[tsne_results[w,1] for w in np.where(kmap[alg] == k)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
